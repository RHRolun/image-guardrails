{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847e3351-c7ed-413e-bc11-89bffada784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install transformers accelerate>=0.26.0\n",
    "!pip install -q diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8416c2b8-9c60-4993-972f-3375b46efe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
    "from transformers import CLIPImageProcessor, CLIPTokenizer, CLIPModel\n",
    "import torch\n",
    "from torchvision.transforms.functional import pil_to_tensor, to_pil_image\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d999581-7cba-41d2-9c69-2f5aa902c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device=\"cuda\"\n",
    "dtype=torch.float16\n",
    "\n",
    "feature_extractor = CLIPImageProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "safety_checker = StableDiffusionSafetyChecker.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-safety-checker\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75053b8b-354f-4430-8b93-b082fce0c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nsfw_embedding(image: PIL_Image, weight: int):\n",
    "    safety_checker_input = feature_extractor(image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    pooled_output  = safety_checker.vision_model(safety_checker_input.pixel_values.to(dtype))[1]\n",
    "    image_embeds = safety_checker.visual_projection(pooled_output)\n",
    "    \n",
    "    safety_checker.concept_embeds = nn.Parameter(torch.cat([safety_checker.concept_embeds, image_embeds]))\n",
    "    safety_checker.concept_embeds_weights = nn.Parameter(torch.cat([safety_checker.concept_embeds_weights, torch.Tensor([0.6]).to(device)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36170f45-aaf6-43ca-949c-5e532a6cf413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_safety_check(image):\n",
    "    safety_checker_input = feature_extractor(image, return_tensors=\"pt\").to(device)\n",
    "    image, has_nsfw_concept = safety_checker(\n",
    "        images=pil_to_tensor(image).unsqueeze(0), clip_input=safety_checker_input.pixel_values.to(dtype)\n",
    "        )\n",
    "    \n",
    "    return has_nsfw_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a547b9-e746-4a5b-b957-b80d7533c414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = PIL_Image.open(\"green-fedora-2.png\").convert(\"RGB\")\n",
    "do_safety_check(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7123c7-ea8b-48d8-bfa9-7c6eefae2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image we don't want to allow\n",
    "image_to_ban = PIL_Image.open(\"green-fedora.png\").convert(\"RGB\")\n",
    "add_nsfw_embedding(image_to_ban, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87925944-27fd-43b2-b1f4-e1e6d81a12fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = PIL_Image.open(\"green-fedora-2.png\").convert(\"RGB\")\n",
    "do_safety_check(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773a8fc4-cab8-42e0-95ce-3d192045ba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = PIL_Image.open(\"cute-cat.jpg\").convert(\"RGB\")\n",
    "do_safety_check(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
